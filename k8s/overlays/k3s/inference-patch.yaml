apiVersion: apps/v1
kind: Deployment
metadata:
  name: inference
spec:
  template:
    spec:
      containers:
        - name: inference
          imagePullPolicy: Always

          resources:
            requests:
              memory: "512Mi"
              cpu: "1000m"
            limits:
              memory: "2Gi"
              cpu: "4000m"

          # Uncomment for TensorRT GPU support
          # resources:
          #   limits:
          #     nvidia.com/gpu: 1
